{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506989a2-021f-4149-a36d-68eec0994f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, concatenate, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "from hyperopt import fmin, tpe, hp, space_eval, Trials, STATUS_OK #, rand\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eda197-35b8-436d-a927-521bc4b04da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the display option for wide dataframes\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e5b23-6d6c-4258-9bee-d995eae85798",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set variables\n",
    "seed = 42  # seed for reproducibility for training\n",
    "\n",
    "k = 4  # k for k-fold cross-validation in hyperparameter tuning\n",
    "max_evals = 30  # Maxomum number of evaluations for hyperparameter tuning \n",
    "seed_tuning = 13  # Seed to split the dataset for hyperparameter tuning\n",
    "\n",
    "N = 10 # experiment repetitions\n",
    "epochs = 30  # number of epochs for training\n",
    "batch_size = 8  # batch size for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861d90e-b035-42c3-bdc0-5256493cc671",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d5704-b3a4-4a3c-8c1c-c2d4068d69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read list of selected patients\n",
    "f = open('Data/selected_patients.txt', 'r')\n",
    "patient_IDs = []\n",
    "for x in f:\n",
    "  patient_IDs.append(int(x.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c396e-9efa-450d-947b-26750694358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load clinical data\n",
    "data = pd.read_csv('Data/clinical_data.csv', header=0, index_col=0, delimiter=';')\n",
    "data = data.loc[patient_IDs]  # Sort the clinical data DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597e159-c6f1-4e2b-8ee0-27f8a4a7d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load images\n",
    "from PIL import Image\n",
    "\n",
    "front = np.asarray([np.array(Image.open(os.path.join('Data/Images/Frontal/',str(ID).zfill(4) + '_front.jpg'))) for ID in patient_IDs])\n",
    "L90 = np.asarray([np.array(Image.open(os.path.join('Data/Images/L90/',str(ID).zfill(4) + '_L90.jpg'))) for ID in patient_IDs])\n",
    "R90 = np.asarray([np.array(Image.open(os.path.join('Data/Images/R90/',str(ID).zfill(4) + '_R90.jpg'))) for ID in patient_IDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecbe21-efcc-4fe8-a723-fd6620c1325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate binary labels\n",
    "diagnosis = data['vx-diagnosis']\n",
    "labels = np.zeros(len(patient_IDs))\n",
    "labels[diagnosis == 'Sick'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569335a0-91b8-46f3-b98c-cff6200b3906",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba246a8-c15f-44d8-9327-95fc5f397d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Min-max normalization\n",
    "M = np.concatenate((front, L90, R90)).max()\n",
    "m = np.concatenate((front, L90, R90)).min()\n",
    "\n",
    "front = ((front - m) / (M - m)).astype('float32')\n",
    "L90 = ((L90 - m) / (M - m)).astype('float32')\n",
    "R90 = ((R90 - m) / (M - m)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8506b-bb47-4332-bdf5-66a782761e3b",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193625e-80e8-47d0-9521-ac111cf534bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CUSTOM METRICS\n",
    "from tensorflow.python.keras.utils import metrics_utils\n",
    "from tensorflow.python.keras.utils.generic_utils import to_list\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "def weighted_error(y_true, y_pred):\n",
    "    WE = 20\n",
    "    \n",
    "    # Convert probabilities/logits to binary predictions\n",
    "    y_pred_binary = tf.round(y_pred)\n",
    "\n",
    "    # False Negatives: predicted 0, actual 1\n",
    "    fn = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred_binary, 0)), tf.float32))\n",
    "\n",
    "    # False Positives: predicted 1, actual 0\n",
    "    fp = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred_binary, 1)), tf.float32))\n",
    "\n",
    "    # Weighted error\n",
    "    return fn * WE + fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003456bf-0c05-4ec7-8ea1-1949cb1d3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(preds_raw, ground_truth):\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, log_loss, roc_auc_score #, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "    \n",
    "    # BCE loss\n",
    "    bce = log_loss(ground_truth, preds_raw)\n",
    "\n",
    "    # Confusion matrix\n",
    "    TN, FP, FN, TP = confusion_matrix(ground_truth, np.round(preds_raw)).ravel()\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)  # accuracy = accuracy_score(ground_truth, np.round(preds_raw))\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    #gmean = np.sqrt((TP/(TP+FN))*(TN/(TN+FP)))\n",
    "    precision = TP / (TP + FP)  # precision = precision_score(ground_truth, np.round(preds_raw))\n",
    "    F1 = 2 * TP / (2*TP + FP + FN)  # F1 = f1_score(ground_truth, np.round(preds_raw))\n",
    "    \n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(ground_truth, preds_raw)\n",
    "    \n",
    "    # Weighted error    \n",
    "    we = weighted_error(ground_truth, np.round(preds_raw))\n",
    "    \n",
    "    results = {\n",
    "        'BCELoss':bce,\n",
    "        'Accuracy':accuracy,\n",
    "        'TP':TP,\n",
    "        'FP':FP,\n",
    "        'TN':TN,\n",
    "        'FN':FN,\n",
    "        'Sensitivity':sensitivity,\n",
    "        'Specificity':specificity,\n",
    "        #'G-mean':gmean,\n",
    "        'Precision':precision,\n",
    "        'Recall':sensitivity,\n",
    "        'F1':F1,\n",
    "        'ROC_AUC':auc,\n",
    "        'WE':we\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487ba92-3b4c-40cc-a3fe-2af5b85cedf7",
   "metadata": {},
   "source": [
    "# Custom CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5eeb51-83e6-4a79-a02e-ceef9e9762ff",
   "metadata": {},
   "source": [
    "## Single-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdfbbc-e873-4da0-b288-f55d9c08caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to check tensor size to see if another downsampling layer can be applied\n",
    "def can_apply_layer(x, min_height, min_width):\n",
    "    \"\"\"Check if the current layer can be applied based on tensor dimensions.\"\"\"\n",
    "    shape = K.int_shape(x)\n",
    "    if shape[1] is None or shape[2] is None:\n",
    "        return False  # Dynamic shape, cannot evaluate\n",
    "    return shape[1] >= min_height and shape[2] >= min_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1f0ea-5a06-45e2-93d6-29e60c929cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "def create_model_singleInput(params, a=480, b=640):\n",
    "            \n",
    "    # Input\n",
    "    stacked_input = Input(shape=(a, b, 3))\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(stacked_input)\n",
    "    x = Conv2D(params['conv1_filters'], kernel_size=params['conv1_kernel'], strides=params['conv1_strides'], activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=params['pool1_size'])(x)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=params['conv2_kernel'], strides=params['conv2_strides'], activation='relu')(x)\n",
    "    if params['add_conv_3']:\n",
    "        x = Conv2D(64, kernel_size=params['conv3_kernel'], activation='relu')(x)\n",
    "    if params['add_conv_4']:\n",
    "        x = Conv2D(64, kernel_size=params['conv4_kernel'], activation='relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        \n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_5']:\n",
    "            x = Conv2D(params['conv5_filters'], kernel_size=params['conv5_kernel'], activation='relu')(x)\n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_6']:\n",
    "            x = Conv2D(params['conv6_filters'], kernel_size=params['conv6_kernel'], activation='relu')(x)\n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_7']:\n",
    "            x = Conv2D(params['conv7_filters'], kernel_size=params['conv7_kernel'], activation='relu')(x)\n",
    "            if can_apply_layer(x, 2, 2):\n",
    "                x = MaxPooling2D((2, 2))(x)\n",
    "                \n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_8']:\n",
    "            x = Conv2D(128, kernel_size=params['conv8_kernel'], activation='relu')(x)\n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_9']:\n",
    "            x = Conv2D(128, kernel_size=params['conv9_kernel'], activation='relu')(x)\n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_10']:\n",
    "            x = Conv2D(128, kernel_size=params['conv10_kernel'], activation='relu')(x)\n",
    "            if can_apply_layer(x, 2, 2):\n",
    "                x = MaxPooling2D((2, 2))(x)\n",
    "                \n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_11']:\n",
    "            x = Conv2D(128, kernel_size=params['conv11_kernel'], activation='relu')(x)\n",
    "    if can_apply_layer(x, 5, 5):\n",
    "        if params['add_conv_12']:\n",
    "            x = Conv2D(128, kernel_size=params['conv12_kernel'], activation='relu')(x)\n",
    "            if can_apply_layer(x, 2, 2):\n",
    "                x = MaxPooling2D((2, 2))(x)\n",
    "        \n",
    "    if can_apply_layer(x, 10, 10):\n",
    "        if params['add_conv_13']:\n",
    "            x = Conv2D(128, kernel_size=params['conv13_kernel'], activation='relu')(x)\n",
    "            x = MaxPooling2D((2, 2))(x)\n",
    "        \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(params['dense1_units'], activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x) \n",
    "    \n",
    "    if params['add_dense_2']:\n",
    "        x = Dense(params['dense2_units'], use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(0.5)(x)   #new\n",
    "\n",
    "    x = Dense(params['dense3_units'], activation='relu')(x)\n",
    "    if params['add_dense_4']:\n",
    "        x = Dense(params['dense4_units'], use_bias=False)(x)\n",
    "    X = Dense(1, activation='sigmoid')(x)   \n",
    "    \n",
    "    ## create the model\n",
    "    return Model(stacked_input, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b310514-11aa-45da-8e23-909b5d1a9b79",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a515d64-a58b-4d60-af6f-374624c7999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_singleInput():\n",
    "    ## Read list of selected patients\n",
    "    f = open('Data/selected_patients.txt', 'r')\n",
    "    patient_IDs = []\n",
    "    for x in f:\n",
    "      patient_IDs.append(int(x.strip()))\n",
    "\n",
    "    ## Load clinical data to get the diagnosis\n",
    "    data = pd.read_csv('Data/clinical_data.csv', header=0, index_col=0, delimiter=';')\n",
    "    data = data.loc[patient_IDs]  # Sort the clinical data DataFrame\n",
    "    \n",
    "    ## Generate binary labels\n",
    "    diagnosis = data['vx-diagnosis']\n",
    "    labels = np.zeros(len(patient_IDs))\n",
    "    labels[diagnosis == 'Sick'] = 1\n",
    "\n",
    "    ## Load images\n",
    "    from PIL import Image\n",
    "    front = np.asarray([np.array(Image.open(os.path.join('Data/Images/Frontal/',str(ID).zfill(4) + '_front.jpg'))) for ID in patient_IDs])\n",
    "    L90 = np.asarray([np.array(Image.open(os.path.join('Data/Images/L90/',str(ID).zfill(4) + '_L90.jpg'))) for ID in patient_IDs])\n",
    "    R90 = np.asarray([np.array(Image.open(os.path.join('Data/Images/R90/',str(ID).zfill(4) + '_R90.jpg'))) for ID in patient_IDs])\n",
    "\n",
    "    ## Normalize (min-max)\n",
    "    M = np.concatenate((front, L90, R90)).max()\n",
    "    m = np.concatenate((front, L90, R90)).min()\n",
    "    front = ((front - m) / (M - m)).astype('float32')\n",
    "    L90 = ((L90 - m) / (M - m)).astype('float32')\n",
    "    R90 = ((R90 - m) / (M - m)).astype('float32')\n",
    "\n",
    "    ## Stack views along the channel dimension\n",
    "    images = np.stack((front[:,:,:,0], L90[:,:,:,0], R90[:,:,:,0]), axis=-1)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b258d64-387d-4b80-818e-dd111f80576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_singleInput(params):\n",
    "    ## Load data\n",
    "    images, labels = data_singleInput()\n",
    "\n",
    "    ## Initialize cross-validation\n",
    "    epochs = 30\n",
    "    batch_size = 8\n",
    "    lr = params['lr']\n",
    "    folds = 5\n",
    "    seed = 13\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    ## Initialize the model\n",
    "    model = create_model_singleInput(params, images.shape[1], images.shape[2])\n",
    "\n",
    "    ## Save the initial weights of the model\n",
    "    initial_weights = model.get_weights()\n",
    "\n",
    "    ## Perform hyperparameter tuning\n",
    "    fold_metrics = []\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(images, labels)):\n",
    "        \n",
    "        print(f\"Fold {i+1}/{folds}\")\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        train_images, val_images = images[train_idx], images[val_idx]\n",
    "        train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        rate_train = sum(train_labels==0)/sum(train_labels)\n",
    "\n",
    "        # Reset the model to initial weights\n",
    "        model.set_weights(initial_weights)\n",
    "\n",
    "        # Train the model\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "        history = model.fit(\n",
    "            train_images, train_labels,\n",
    "            class_weight={0: 1, 1: rate_train},\n",
    "            validation_data=(val_images, val_labels),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0  # Suppress training output\n",
    "        )\n",
    "\n",
    "        # Record the best validation AUC for this fold\n",
    "        best_auc = max(history.history['val_AUC'])\n",
    "        fold_metrics.append(best_auc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    # Return the negative mean AUC across all folds as the loss\n",
    "    print(f'Max test ROC AUC in each fold: {fold_metrics}')\n",
    "    mean_auc = np.mean(fold_metrics)\n",
    "    return -mean_auc  # Maximize AUC by minimizing its negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e585cf-d0f6-4035-8dea-71aa216b71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search space\n",
    "space_singleInput = {\n",
    "    'lr': hp.loguniform('lr', np.log(1e-5), np.log(1e-2)),\n",
    "\n",
    "    'conv1_filters': hp.choice('conv1_filters', [32, 64]),\n",
    "    'conv1_kernel': hp.choice('conv1_kernel', [(3, 3), (5, 5)]),\n",
    "    'conv1_strides': hp.choice('conv1_strides', [1, 2]),\n",
    "    'pool1_size': hp.choice('pool1_size', [2, 3]),\n",
    "    'conv2_kernel': hp.choice('conv2_kernel', [(3, 3), (5, 5)]),\n",
    "    'conv2_strides': hp.choice('conv2_strides', [1, 2]),\n",
    "    'add_conv_3' : hp.choice('add_conv_3', [True, False]),\n",
    "    'conv3_kernel': hp.choice('conv3_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_4' : hp.choice('add_conv_4', [True, False]),\n",
    "    'conv4_kernel': hp.choice('conv4_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_5' : hp.choice('add_conv_5', [True, False]),\n",
    "    'conv5_filters': hp.choice('conv5_filters', [64, 128]),\n",
    "    'conv5_kernel': hp.choice('conv5_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_6' : hp.choice('add_conv_6', [True, False]),\n",
    "    'conv6_filters': hp.choice('conv6_filters', [64, 128]),\n",
    "    'conv6_kernel': hp.choice('conv6_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_7' : hp.choice('add_conv_7', [True, False]),\n",
    "    'conv7_filters': hp.choice('conv7_filters', [64, 128]),\n",
    "    'conv7_kernel': hp.choice('conv7_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_8' : hp.choice('add_conv_8', [True, False]),\n",
    "    'conv8_kernel': hp.choice('conv8_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_9' : hp.choice('add_conv_9', [True, False]),\n",
    "    'conv9_kernel': hp.choice('conv9_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_10' : hp.choice('add_conv_10', [True, False]),\n",
    "    'conv10_kernel': hp.choice('conv10_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_11' : hp.choice('add_conv_11', [True, False]),\n",
    "    'conv11_kernel': hp.choice('conv11_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_12' : hp.choice('add_conv_12', [True, False]),\n",
    "    'conv12_kernel': hp.choice('conv12_kernel', [(3, 3), (5, 5)]),\n",
    "    'add_conv_13' : hp.choice('add_conv_13', [True, False]),\n",
    "    'conv13_kernel': hp.choice('conv13_kernel', [(3, 3), (5, 5)]),\n",
    "    \n",
    "    'dense1_units': hp.choice('dense1_units', [256, 512]),\n",
    "    'add_dense_2' : hp.choice('add_dense_2', [True, False]),\n",
    "    'dense2_units': hp.choice('dense2_units', [64, 128]),\n",
    "    'dense3_units': hp.choice('dense3_units', [32, 64]),\n",
    "    'add_dense_4' : hp.choice('add_dense_4', [True, False]),\n",
    "    'dense4_units': hp.choice('dense4_units', [32, 64])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83beb30-4036-4d37-ad4a-7d57670330d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter tuning\n",
    "# Create trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run optimization\n",
    "ti = time.time()\n",
    "best_singleInput = fmin(\n",
    "    fn=objective_singleInput,\n",
    "    space=space_singleInput,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials\n",
    ")\n",
    "tuningTime = time.time() - ti\n",
    "\n",
    "hours, remainder = divmod(tuningTime, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f'Hyperparameter tuning took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "print(\"Best hyperparameters:\", space_eval(space, best_singleInput))\n",
    "\n",
    "# Save the results\n",
    "json_compatible_params = {\n",
    "    key: (list(value) if isinstance(value, tuple) else value)\n",
    "    for key, value in space_eval(space_singleInput, best_singleInput).items()\n",
    "}\n",
    "with open('Parameters_singleInputCNN.json', \"w\") as f:\n",
    "    json.dump(json_compatible_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d57614-3093-49cf-be78-b79c6670f128",
   "metadata": {},
   "source": [
    "### Train N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ef4c3-69d7-4739-bc20-211e6d85e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read tuned hyperparameters\n",
    "with open(\"Parameters_singleInputCNN.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "lr = params['lr']\n",
    "params.pop('lr')\n",
    "\n",
    "# Convert lists back to tuples if needed\n",
    "params = {\n",
    "    key: (tuple(value) if isinstance(value, list) else value)\n",
    "    for key, value in params.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa6190-d2d6-4a7a-98a1-921e1e71dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61105d7-4414-4814-b554-e49d3f1955b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the splitter to split the dataset into 85% train and 15% tests sets N times \n",
    "splitter = StratifiedShuffleSplit(n_splits=N, test_size=int(round(0.15*len(labels))), random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d2a09-2eae-4d8d-a198-1ca4e19a4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial, (train_index, test_index) in enumerate(splitter.split(front, labels)):\n",
    "    \n",
    "    print(f'Trial {trial + 1}'), print()\n",
    "\n",
    "    ## Split the dataset into train (85%) and test (15%) sets\n",
    "    train_front = front[train_index]\n",
    "    train_L90 = L90[train_index]\n",
    "    train_R90 = R90[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "    \n",
    "    test_front = front[test_index]\n",
    "    test_L90 = L90[test_index]\n",
    "    test_R90 = R90[test_index]\n",
    "    test_labels = labels[test_index]\n",
    "\n",
    "    ## Stack views along the channel dimension\n",
    "    images_train = np.stack((train_front[:,:,:,0], train_L90[:,:,:,0], train_R90[:,:,:,0]), axis=-1)\n",
    "    images_test = np.stack((test_front[:,:,:,0], test_L90[:,:,:,0], test_R90[:,:,:,0]), axis=-1)\n",
    "\n",
    "    ## Calculate the weight for training to address class imbalance\n",
    "    rate_train = sum(train_labels == 0) / sum(train_labels)\n",
    "\n",
    "    ## Initialize and compile the model\n",
    "    model = create_model_singleInput(params, front.shape[1], front.shape[2])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],\n",
    "                  optimizer=SGD(learning_rate=lr, clipvalue=1.0))\n",
    "    \n",
    "    ## Train the model\n",
    "    ti = time.time()\n",
    "    history = model.fit(images_train, train_labels, class_weight = {0: 1, 1: rate_train}, \n",
    "                        validation_data = (images_test, test_labels),\n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        #callbacks=[NaNCheckCallback()],\n",
    "                        verbose=0\n",
    "                       ) \n",
    "    train_time = time.time() - ti\n",
    "\n",
    "    hours, remainder = divmod(train_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "    ## Save learning curves\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(epochs), history.history['loss'], label='Train Loss')\n",
    "    plt.plot(range(epochs), history.history['val_loss'], label='Test Loss')\n",
    "    plt.legend(loc='upper right',fontsize=10)\n",
    "    plt.title('Train and Test Loss',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(epochs), history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test Accuracy',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(epochs), history.history['AUC'], label='Train AUC')\n",
    "    plt.plot(range(epochs), history.history['val_AUC'], label='Test AUC')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test ROC AUC',fontsize=12)\n",
    "    \n",
    "    plt.savefig('Learning_curves/singleInputCNN_'+str(trial+1)+'.png'), plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    ## Save the model\n",
    "    model.save('Models/singleInputCNN_'+str(trial+1)+'.h5')\n",
    "\n",
    "    ## Print the number of parameters in the model\n",
    "    total_params = model.count_params()  # total_params = np.sum([np.prod(v.shape.as_list()) for v in model.variables])\n",
    "    trainable_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_variables])\n",
    "    print(f'Classifier has {total_params} total parameters, {trainable_params} of which are trainable.'), print()\n",
    "    \n",
    "    ## Predict\n",
    "    train_preds = model.predict(images_train)\n",
    "    np.save('Predictions/singleInputCNN_train_'+str(trial+1)+'.npy',train_preds)\n",
    "    test_preds = model.predict(images_test)\n",
    "    np.save('Predictions/singleInputCNN_test_'+str(trial+1)+'.npy',test_preds)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    results_train = evaluate_model(train_preds, train_labels)\n",
    "    print('TRAIN results:')\n",
    "    for metric, value in results_train.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    results_test = evaluate_model(test_preds, test_labels)\n",
    "    print('TEST results:')\n",
    "    for metric, value in results_test.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    ## Store results\n",
    "    trials_results.append(\n",
    "        {'classifier':'singleInputCNN',\n",
    "         'trial':trial+1,\n",
    "         'parameters':trainable_params,\n",
    "         'trainTime':train_time,\n",
    "         **{'train_'+k:v for k,v in results_train.items()},\n",
    "         **{'test_'+k:v for k,v in results_test.items()}\n",
    "        }\n",
    "    )    \n",
    "\n",
    "    ## Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    print(), print(100*'#'), print()\n",
    "\n",
    "pd.DataFrame(trials_results).to_csv('CNN_Results_'+str(N)+'trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537391d-9973-47a3-a82d-7b7c1b237318",
   "metadata": {},
   "source": [
    "## Multi-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b6f99-8bfb-4719-8495-e91c2a35ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "def create_model_multiInput(params, a=480, b=640):\n",
    "\n",
    "    ## Front\n",
    "    front_input = Input(shape=(a, b, 1))\n",
    "    front = Conv2D(32, (3, 3), activation='relu')(front_input)\n",
    "    front = Conv2D(64, kernel_size=params['front_conv1_kernel'], strides=params['front_conv1_strides'], activation='relu')(front)  # strides=2\n",
    "    front = MaxPooling2D((2, 2))(front)\n",
    "    front = Conv2D(params['front_conv2_filters'], kernel_size=params['front_conv2_kernel'], activation='relu')(front)  #256, 128\n",
    "    front = Conv2D(params['front_conv3_filters'], kernel_size=params['front_conv3_kernel'], activation='relu')(front)  #64\n",
    "    front = MaxPooling2D((2, 2))(front)\n",
    "    front = Flatten()(front) \n",
    "    front = Dense(params['front_dense1_units'], activation='relu')(front)  #256, 512\n",
    "    if params['front_add_dense2']:\n",
    "        front = Dropout(0.5)(front)\n",
    "        front = Dense(params['front_dense2_units'], activation='relu')(front)  #128, 256 \n",
    "    \n",
    "    ## L90\n",
    "    L90_input = Input(shape=(a, b, 1))\n",
    "    L90 = Conv2D(32, (3, 3), activation='relu')(L90_input)\n",
    "    L90 = Conv2D(params['L90_conv1_filters'], kernel_size=params['L90_conv1_kernel'], activation='relu')(L90)  #64\n",
    "    L90 = MaxPooling2D((2, 2))(L90)\n",
    "    L90 = Conv2D(params['L90_conv2_filters'], kernel_size=params['L90_conv2_kernel'], strides=2, activation='relu')(L90)  #128\n",
    "    #L90 = Conv2D(64, (5, 5), activation='relu')(L90) \n",
    "    if params['L90_add_conv3']:\n",
    "        L90 = Conv2D(params['L90_conv3_filters'], kernel_size=params['L90_conv3_kernel'], activation='relu')(L90) \n",
    "    L90 = Conv2D(params['L90_conv4_filters'], kernel_size=params['L90_conv4_kernel'], activation='relu')(L90) # 64, (5, 5)\n",
    "    L90 = MaxPooling2D((2, 2))(L90)\n",
    "    L90 = Flatten()(L90)\n",
    "    L90 = Dense(256, activation='relu')(L90)  \n",
    "    #L90 = Dropout(0.5)(L90)\n",
    "    #L90 = Dense(128, activation='relu')(L90)\n",
    "    \n",
    "    ## R90\n",
    "    R90_input = Input(shape=(a, b, 1))\n",
    "    R90 = Conv2D(32, (3, 3), activation='relu')(R90_input)\n",
    "    R90 = Conv2D(params['R90_conv1_filters'], kernel_size=params['R90_conv1_kernel'], activation='relu')(R90)   \n",
    "    R90 = MaxPooling2D((2, 2))(R90)\n",
    "    R90 = Conv2D(params['R90_conv2_filters'], kernel_size=params['R90_conv2_kernel'], strides=2, activation='relu')(R90)  #128\n",
    "    #R90 = Conv2D(64, (5, 5), activation='relu')(R90)  \n",
    "    if params['R90_add_conv3']:\n",
    "        R90 = Conv2D(params['R90_conv3_filters'], kernel_size=params['R90_conv3_kernel'], activation='relu')(R90) \n",
    "    R90 = Conv2D(params['R90_conv4_filters'], kernel_size=params['R90_conv4_kernel'], activation='relu')(R90)  # 64, (5, 5)\n",
    "    R90 = MaxPooling2D((2, 2))(R90)\n",
    "    R90 = Flatten()(R90)\n",
    "    R90 = Dense(256, activation='relu')(R90)  \n",
    "    #R90 = Dropout(0.5)(R90)\n",
    "    #R90 = Dense(128, activation='relu')(R90)\n",
    "\n",
    "    ## concatenate all the outputs of each stalk of the net.\n",
    "    concatenated = concatenate([front, L90, R90], axis=-1)\n",
    "    x = Dense(params['dense1_units'], activation='relu')(concatenated)  ## antes 512, 256\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x) \n",
    "\n",
    "    if params['add_dense2']:\n",
    "        x = Dense(params['dense2_units'], use_bias=False)(x)  ## 64\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        #x = Dense(64, activation='relu')(x)  ## 64, 128\n",
    "        #x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)   #new\n",
    "\n",
    "    x = Dense(params['dense3_units'], activation='relu')(x)   # <-- batchnorm en esta capa funciona mal\n",
    "    X = Dense(1, activation='sigmoid')(x)   \n",
    "            \n",
    "    ## create the model\n",
    "    return Model([front_input, L90_input, R90_input], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60748e4-10fa-49d4-a4a9-65238995ee41",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030a789-29c6-4ecc-a42b-07bf27266fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_multieInput():\n",
    "    ## Read list of selected patients\n",
    "    f = open('Data/selected_patients.txt', 'r')\n",
    "    patient_IDs = []\n",
    "    for x in f:\n",
    "      patient_IDs.append(int(x.strip()))\n",
    "\n",
    "    ## Load clinical data to get the diagnosis\n",
    "    data = pd.read_csv('Data/clinical_data.csv', header=0, index_col=0, delimiter=';')\n",
    "    data = data.loc[patient_IDs]  # Sort the clinical data DataFrame\n",
    "    \n",
    "    ## Generate binary labels\n",
    "    diagnosis = data['vx-diagnosis']\n",
    "    labels = np.zeros(len(patient_IDs))\n",
    "    labels[diagnosis == 'Sick'] = 1\n",
    "\n",
    "    ## Load images\n",
    "    from PIL import Image\n",
    "    front = np.asarray([np.array(Image.open(os.path.join('Data/Images/Frontal/',str(ID).zfill(4) + '_front.jpg'))) for ID in patient_IDs])\n",
    "    L90 = np.asarray([np.array(Image.open(os.path.join('Data/Images/L90/',str(ID).zfill(4) + '_L90.jpg'))) for ID in patient_IDs])\n",
    "    R90 = np.asarray([np.array(Image.open(os.path.join('Data/Images/R90/',str(ID).zfill(4) + '_R90.jpg'))) for ID in patient_IDs])\n",
    "\n",
    "    ## Normalize (min-max)\n",
    "    M = np.concatenate((front, L90, R90)).max()\n",
    "    m = np.concatenate((front, L90, R90)).min()\n",
    "    front = ((front - m) / (M - m)).astype('float32')\n",
    "    L90 = ((L90 - m) / (M - m)).astype('float32')\n",
    "    R90 = ((R90 - m) / (M - m)).astype('float32')\n",
    "\n",
    "    ## Convert 3-channel to 1-channel images\n",
    "    front = np.expand_dims(front[:,:,:,0], -1)\n",
    "    L90 = np.expand_dims(L90[:,:,:,0], -1)\n",
    "    R90 = np.expand_dims(R90[:,:,:,0], -1)\n",
    "    \n",
    "    return [front, L90, R90], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e631961-9d14-429c-9777-445795c68254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_multiInput(params):\n",
    "    ## Load data\n",
    "    images, labels = data_multiInput()\n",
    "    front, L90, R90 = images\n",
    "\n",
    "    ## Initialize cross-validation\n",
    "    epochs = 30\n",
    "    batch_size = 8\n",
    "    lr = params['lr']\n",
    "    folds = 5\n",
    "    seed = 13\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    ## Initialize the model\n",
    "    model = create_model_multiInput(params, front.shape[1], front.shape[2])\n",
    "\n",
    "    ## Save the initial weights of the model\n",
    "    initial_weights = model.get_weights()\n",
    "\n",
    "    ## Perform hyperparameter tuning\n",
    "    fold_metrics = []\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(front, labels)):\n",
    "        \n",
    "        print(f\"Fold {i+1}/{folds}\")\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        train_front, val_front = front[train_idx], front[val_idx]\n",
    "        train_L90, val_L90 = L90[train_idx], L90[val_idx]\n",
    "        train_R90, val_R90 = R90[train_idx], R90[val_idx]\n",
    "        train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        rate_train = sum(train_labels==0)/sum(train_labels)\n",
    "\n",
    "        # Reset the model to initial weights\n",
    "        model.set_weights(initial_weights)\n",
    "\n",
    "        # Train the model\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "        history = model.fit(\n",
    "            [train_front, train_L90, train_R90], train_labels,\n",
    "            class_weight={0: 1, 1: rate_train},\n",
    "            validation_data=([val_front, val_L90, val_R90], val_labels),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            #callbacks=[NaNCheckCallback()],\n",
    "            verbose=0  # Suppress training output\n",
    "        )\n",
    "\n",
    "        # Record the best validation AUC for this fold\n",
    "        best_auc = max(history.history['val_AUC'])\n",
    "        fold_metrics.append(best_auc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    # Return the negative mean AUC across all folds as the loss\n",
    "    print(f'Max test ROC AUC in each fold: {fold_metrics}')\n",
    "    mean_auc = np.mean(fold_metrics)\n",
    "    return -mean_auc  # Maximize AUC by minimizing its negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637adc6-c1d9-4406-9cea-becbf2c10e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search space\n",
    "space_multiInput = {\n",
    "    'lr': hp.loguniform('lr', np.log(1e-5), np.log(1e-2)),\n",
    "    \n",
    "    'front_conv1_kernel': hp.choice('front_conv1_kernel', [(3, 3), (5, 5)]),\n",
    "    'front_conv1_strides': hp.choice('front_conv1_strides', [1, 2]),\n",
    "    'front_conv2_filters': hp.choice('front_conv2_filters', [64, 128, 256]),\n",
    "    'front_conv2_kernel': hp.choice('front_conv2_kernel', [(3, 3), (5, 5)]),\n",
    "    'front_conv3_filters': hp.choice('front_conv3_filters', [64, 128]),\n",
    "    'front_conv3_kernel': hp.choice('front_conv3_kernel', [(3, 3), (5, 5)]),\n",
    "    'front_dense1_units': hp.choice('front_dense1_units', [256, 512]),\n",
    "    'front_add_dense2' : hp.choice('front_add_dense2', [True, False]),\n",
    "    'front_dense2_units': hp.choice('front_dense2_units', [128, 256]),\n",
    "\n",
    "    'L90_conv1_filters': hp.choice('L90_conv1_filters', [32, 64]),\n",
    "    'L90_conv1_kernel': hp.choice('L90_conv1_kernel', [(3, 3), (5, 5)]),\n",
    "    'L90_conv2_filters': hp.choice('L90_conv2_filters', [64, 128]),\n",
    "    'L90_conv2_kernel': hp.choice('L90_conv2_kernel', [(3, 3), (5, 5)]),\n",
    "    'L90_add_conv3' : hp.choice('L90_add_conv3', [True, False]),\n",
    "    'L90_conv3_filters': hp.choice('L90_conv3_filters', [64, 128]),\n",
    "    'L90_conv3_kernel': hp.choice('L90_conv3_kernel', [(3, 3), (5, 5)]),\n",
    "    'L90_conv4_filters': hp.choice('L90_conv4_filters', [64, 128]),\n",
    "    'L90_conv4_kernel': hp.choice('L90_conv4_kernel', [(3, 3), (5, 5)]),\n",
    "\n",
    "    'R90_conv1_filters': hp.choice('R90_conv1_filters', [32, 64]),\n",
    "    'R90_conv1_kernel': hp.choice('R90_conv1_kernel', [(3, 3), (5, 5)]),\n",
    "    'R90_conv2_filters': hp.choice('R90_conv2_filters', [64, 128]),\n",
    "    'R90_conv2_kernel': hp.choice('R90_conv2_kernel', [(3, 3), (5, 5)]),\n",
    "    'R90_add_conv3' : hp.choice('R90_add_conv3', [True, False]),\n",
    "    'R90_conv3_filters': hp.choice('R90_conv3_filters', [64, 128]),\n",
    "    'R90_conv3_kernel': hp.choice('R90_conv3_kernel', [(3, 3), (5, 5)]),\n",
    "    'R90_conv4_filters': hp.choice('R90_conv4_filters', [64, 128]),\n",
    "    'R90_conv4_kernel': hp.choice('R90_conv4_kernel', [(3, 3), (5, 5)]),\n",
    "\n",
    "    'dense1_units': hp.choice('dense1_units', [256, 512]),\n",
    "    'add_dense2' : hp.choice('add_dense2', [True, False]),\n",
    "    'dense2_units': hp.choice('dense2_units', [64, 128]),\n",
    "    'dense3_units': hp.choice('dense3_units', [32, 64])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2e9ba-4573-426b-969b-79e5f0bce6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter tuning\n",
    "# Create trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run optimization\n",
    "ti = time.time()\n",
    "best_multiInput = fmin(\n",
    "    fn=objective_multiInput,\n",
    "    space=space_multiInput,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials\n",
    ")\n",
    "tuningTime = time.time() - ti\n",
    "\n",
    "hours, remainder = divmod(tuningTime, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f'Hyperparameter tuning took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "print(\"Best hyperparameters:\", space_eval(space, best_multiInput))\n",
    "\n",
    "# Save the results\n",
    "json_compatible_params = {\n",
    "    key: (list(value) if isinstance(value, tuple) else value)\n",
    "    for key, value in space_eval(space_multiInput, best_multiInput).items()\n",
    "}\n",
    "with open('Parameters_multiInputCNN.json', \"w\") as f:\n",
    "    json.dump(json_compatible_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e3728-6bfb-4953-aa99-bcde95666552",
   "metadata": {},
   "source": [
    "### Train N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f1bf5-e130-4c75-b55c-fc836bab9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read tuned hyperparameters\n",
    "with open(\"Parameters_multiInputCNN.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "lr = params['lr']\n",
    "params.pop('lr')\n",
    "\n",
    "# Convert lists back to tuples if needed\n",
    "params = {\n",
    "    key: (tuple(value) if isinstance(value, list) else value)\n",
    "    for key, value in params.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28767c78-bb25-406e-82d8-03ee428dae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = pd.read_csv('CNN_Results_'+str(N)+'trials.csv', index_col = 0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f379c-99a4-4214-8bca-4394937e2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the splitter to split the dataset into 85% train and 15% tests sets N times \n",
    "splitter = StratifiedShuffleSplit(n_splits=N, test_size=int(round(0.15*len(labels))), random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a33b2-3517-486f-a217-3fadf18d7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial, (train_index, test_index) in enumerate(splitter.split(front, labels)):\n",
    "    \n",
    "    print(f'Trial {trial + 1}'), print()\n",
    "\n",
    "    ## Split the dataset into train (85%) and test (15%) sets\n",
    "    train_front = front[train_index]\n",
    "    train_L90 = L90[train_index]\n",
    "    train_R90 = R90[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "    \n",
    "    test_front = front[test_index]\n",
    "    test_L90 = L90[test_index]\n",
    "    test_R90 = R90[test_index]\n",
    "    test_labels = labels[test_index]\n",
    "\n",
    "    ## Convert 3-channel to 1-channel images\n",
    "    train_front = np.expand_dims(train_front[:,:,:,0], -1)\n",
    "    train_L90 = np.expand_dims(train_L90[:,:,:,0], -1)\n",
    "    train_R90 = np.expand_dims(train_R90[:,:,:,0], -1)\n",
    "    \n",
    "    test_front = np.expand_dims(test_front[:,:,:,0], -1)\n",
    "    test_L90 = np.expand_dims(test_L90[:,:,:,0], -1)\n",
    "    test_R90 = np.expand_dims(test_R90[:,:,:,0], -1)\n",
    "\n",
    "    ## Calculate the weight for training to address class imbalance\n",
    "    rate_train = sum(train_labels == 0) / sum(train_labels)\n",
    "\n",
    "    ## Initialize and compile the model\n",
    "    model = create_model_multiInput(params, front.shape[1], front.shape[2])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],  \n",
    "                  optimizer=SGD(learning_rate=lr, clipvalue=1.0))\n",
    "    \n",
    "    ## Train the model\n",
    "    ti = time.time()\n",
    "    history = model.fit([train_front, train_L90, train_R90], train_labels, class_weight = {0: 1, 1: rate_train}, \n",
    "                        validation_data = ([test_front, test_L90, test_R90], test_labels),\n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        #callbacks=[NaNCheckCallback()],\n",
    "                        verbose=0\n",
    "                       ) \n",
    "    train_time = time.time() - ti\n",
    "\n",
    "    hours, remainder = divmod(train_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "    ## Save learning curves\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(epochs), history.history['loss'], label='Train Loss')\n",
    "    plt.plot(range(epochs), history.history['val_loss'], label='Test Loss')\n",
    "    plt.legend(loc='upper right',fontsize=10)\n",
    "    plt.title('Train and Test Loss',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(epochs), history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test Accuracy',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(epochs), history.history['AUC'], label='Train AUC')\n",
    "    plt.plot(range(epochs), history.history['val_AUC'], label='Test AUC')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test ROC AUC',fontsize=12)\n",
    "    \n",
    "    plt.savefig('Learning_curves/multiInputCNN_'+str(trial+1)+'.png'), plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    ## Save the model\n",
    "    model.save('Models/multiInputCNN_'+str(trial+1)+'.h5')\n",
    "\n",
    "    ## Print the number of parameters in the model\n",
    "    total_params = model.count_params()  # total_params = np.sum([np.prod(v.shape.as_list()) for v in model.variables])\n",
    "    trainable_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_variables])\n",
    "    print(f'Classifier has {total_params} total parameters, {trainable_params} of which are trainable.'), print()\n",
    "    \n",
    "    ## Predict\n",
    "    train_preds = model.predict([train_front, train_L90, train_R90])\n",
    "    np.save('Predictions/multiInputCNN_train_'+str(trial+1)+'.npy',train_preds)\n",
    "    test_preds = model.predict([test_front, test_L90, test_R90])\n",
    "    np.save('Predictions/multiInputCNN_test_'+str(trial+1)+'.npy',test_preds)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    results_train = evaluate_model(train_preds, train_labels)\n",
    "    print('TRAIN results:')\n",
    "    for metric, value in results_train.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    results_test = evaluate_model(test_preds, test_labels)\n",
    "    print('TEST results:')\n",
    "    for metric, value in results_test.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    ## Store results\n",
    "    trials_results.append(\n",
    "        {'classifier':'multiInputCNN',\n",
    "         'trial':trial+1,\n",
    "         'parameters':trainable_params,\n",
    "         'trainTime':train_time,\n",
    "         **{'train_'+k:v for k,v in results_train.items()},\n",
    "         **{'test_'+k:v for k,v in results_test.items()}\n",
    "        }\n",
    "    )    \n",
    "\n",
    "    ## Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    print(), print(100*'#'), print()\n",
    "\n",
    "pd.DataFrame(trials_results).to_csv('CNN_Results_'+str(N)+'trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396aa336-f38c-451a-9e62-16f7c4641139",
   "metadata": {},
   "source": [
    "# Pre-trained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85536bfd-003f-4c8a-87da-5159838fbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of top layers to unfreeze during second step of fine-tuning\n",
    "perc_unfreeze = 0.2\n",
    "epochs_freeze = epochs//2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cd702-06d1-4ac9-bab2-1c9684ab8cf9",
   "metadata": {},
   "source": [
    "## Functions for hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a695c77-05eb-4e50-8e3d-689eb0b76c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperopt objective function\n",
    "def objective_preTrainedCNN(params, baseModel_fn):\n",
    "\n",
    "    ## Load data\n",
    "    images, labels = data_singleInput()\n",
    "\n",
    "    ## Initialize cross-validation\n",
    "    epochs = 30\n",
    "    epochs_freeze = epochs//2\n",
    "    perc_unfreeze = 0.2\n",
    "    lr_freeze = params['lr_freeze']\n",
    "    lr_unfreeze = params['lr_unfreeze']\n",
    "    batch_size = 8\n",
    "    folds = 5\n",
    "    seed = 13\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    ## Initialize the model\n",
    "    # Load the base model\n",
    "    baseModel = baseModel_fn(weights='imagenet', include_top=False, input_shape=(images.shape[1], images.shape[2], 3))\n",
    "\n",
    "    # Initially freeze all layers of the base model\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Build the full model\n",
    "    model = Sequential()\n",
    "    model.add(baseModel)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    ## Save the initial weights of the model\n",
    "    initial_weights = model.get_weights()\n",
    "\n",
    "    ## Perform hyperparameter tuning\n",
    "    fold_metrics = []\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(images, labels)):\n",
    "        \n",
    "        print(f\"Fold {i+1}/{folds}\")\n",
    "        \n",
    "        ## Split the data into training and validation sets\n",
    "        train_images, val_images = images[train_idx], images[val_idx]\n",
    "        train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        rate_train = sum(train_labels==0)/sum(train_labels)\n",
    "\n",
    "        ## Reset the model to initial weights\n",
    "        model.set_weights(initial_weights)\n",
    "        \n",
    "\n",
    "        ## Step 1: Train only the fully connected layers\n",
    "        optimizer = SGD(learning_rate=lr_freeze)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_images, train_labels,\n",
    "            class_weight={0: 1, 1: rate_train},\n",
    "            validation_data=(val_images, val_labels),\n",
    "            epochs=epochs_freeze,\n",
    "            batch_size=batch_size,\n",
    "            #callbacks=[NaNCheckCallback()],\n",
    "            verbose=0  # Suppress training output\n",
    "        )\n",
    "\n",
    "        # Print the best validation AUC for in this step\n",
    "        best_auc_1 = max(history.history['val_AUC'])\n",
    "        print(f'Max test ROC AUC after step 1 of fine-tuning: {best_auc_1}')\n",
    "        print()\n",
    "        \n",
    "\n",
    "        ## Step 2: Unfreeze part of the base model\n",
    "        total_layers = len(baseModel.layers)\n",
    "        unfreeze_layers = int(total_layers * perc_unfreeze)\n",
    "\n",
    "        for layer in baseModel.layers[total_layers - unfreeze_layers:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Recompile the model with a reduced learning rate\n",
    "        optimizer = SGD(learning_rate=lr_unfreeze)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "        # Train the model for fine-tuning\n",
    "        history = model.fit(\n",
    "            train_images, train_labels,\n",
    "            class_weight={0: 1, 1: rate_train},\n",
    "            validation_data=(val_images, val_labels),\n",
    "            epochs=epochs-epochs_freeze,\n",
    "            batch_size=batch_size,\n",
    "            #callbacks=[NaNCheckCallback()],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Print the best validation AUC for in this step\n",
    "        best_auc = max(history.history['val_AUC'])\n",
    "        print(f'Max test ROC AUC after step 2 of fine-tuning: {best_auc}')\n",
    "        fold_metrics.append(best_auc)\n",
    "\n",
    "        print()        \n",
    "\n",
    "    # Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    # Return the negative mean AUC across all folds as the loss\n",
    "    print(f'Max test ROC AUC in each fold: {fold_metrics}')\n",
    "    mean_auc = np.mean(fold_metrics)\n",
    "    return -mean_auc  # Maximize AUC by minimizing its negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81861de4-1e7f-4580-92f0-21baece37b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperopt search space\n",
    "space_preTrainedCNN = {\n",
    "    'lr_freeze': hp.loguniform('lr_freeze', np.log(1e-5), np.log(1e-2)),\n",
    "    'lr_unfreeze': hp.loguniform('lr_unfreeze', np.log(1e-6), np.log(1e-3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801c669-e802-430c-baec-d04bab876948",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_pt = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c2341-3d5d-4eb4-a944-2b821e6ec647",
   "metadata": {},
   "source": [
    "## VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809af74-0689-4996-931d-431d021fd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6ac56-f395-44b7-9b6e-29cffb76e208",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b119cf7-86cd-4fc8-8344-dec191c374bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter tuning\n",
    "# Objective function for the specific pre-trained CNN\n",
    "objective_pt = lambda params: objective_preTrainedCNN(params, VGG16)\n",
    "\n",
    "# Create trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run optimization\n",
    "ti = time.time()\n",
    "best = fmin(\n",
    "    fn=objective_pt,\n",
    "    space=space_preTrainedCNN,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials = trials\n",
    ")\n",
    "tuningTime = time.time() - ti\n",
    "\n",
    "hours, remainder = divmod(tuningTime, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f'Hyperparameter tuning took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "print(\"Best hyperparameters:\", space_eval(space_preTrainedCNN, best))\n",
    "\n",
    "learning_rates_pt['VGG16'] = {'lr_freeze' : best['lr_freeze'], 'lr_unfreeze' : best['lr_unfreeze']}\n",
    "\n",
    "# Plot the parameter tuning process\n",
    "lrs_freeze = np.asarray([trial['misc']['vals']['lr_freeze'][0] for trial in trials.trials])\n",
    "lrs_unfreeze = np.asarray([trial['misc']['vals']['lr_unfreeze'][0] for trial in trials.trials])\n",
    "losses = np.asarray([trial['result']['loss'] for trial in trials.trials])\n",
    "    \n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(lrs_freeze, lrs_unfreeze, -losses, c=losses, cmap='viridis', label='Loss vs. Learning Rates')\n",
    "ax.set_xlabel('Learning Rate for Step 1')\n",
    "ax.set_ylabel('Learning Rate for Step 2')\n",
    "ax.set_zlabel('Mean ROC AUC')\n",
    "ax.set_title('Hyperparameter Tuning: ROC AUC vs. Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.savefig('Parameter_tuning/LearningRate_tuning/VGG16.png'), plt.show()\n",
    "plt.show()\n",
    "    \n",
    "# Save the results\n",
    "pd.DataFrame(learning_rates_pt).to_csv('Parameters_preTrainedCNNs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b474f8-5b8f-465c-8f12-e11507fa6943",
   "metadata": {},
   "source": [
    "### Train N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a1349-954f-4613-b771-fa078f20755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_pt = pd.read_csv('Parameters_preTrainedCNNs.csv', index_col = 0)\n",
    "trials_results = pd.read_csv('CNN_Results_'+str(N)+'trials.csv', index_col = 0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569d54b-4f30-4fb9-8399-f251705edcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the splitter to split the dataset into 85% train and 15% tests sets N times \n",
    "splitter = StratifiedShuffleSplit(n_splits=N, test_size=int(round(0.15*len(labels))), random_state = seed)\n",
    "\n",
    "# Get the tuned learning rates\n",
    "lr_freeze = learning_rates_pt['VGG16']['lr_freeze']\n",
    "lr_unfreeze = learning_rates_pt['VGG16']['lr_unfreeze']\n",
    "    \n",
    "for trial, (train_index, test_index) in enumerate(splitter.split(front, labels)):\n",
    "        \n",
    "    print(f'Trial {trial + 1}'), print()\n",
    "\n",
    "    ## Split the dataset into train (85%) and test (15%) sets\n",
    "    train_front = front[train_index]\n",
    "    train_L90 = L90[train_index]\n",
    "    train_R90 = R90[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "        \n",
    "    test_front = front[test_index]\n",
    "    test_L90 = L90[test_index]\n",
    "    test_R90 = R90[test_index]\n",
    "    test_labels = labels[test_index]\n",
    "    \n",
    "    ## Stack views along the channel dimension\n",
    "    images_train = np.stack((train_front[:,:,:,0], train_L90[:,:,:,0], train_R90[:,:,:,0]), axis=-1)\n",
    "    images_test = np.stack((test_front[:,:,:,0], test_L90[:,:,:,0], test_R90[:,:,:,0]), axis=-1)\n",
    "    \n",
    "    ## Calculate the weight for training to address class imbalance\n",
    "    rate_train = sum(train_labels == 0) / sum(train_labels)\n",
    "    \n",
    "    ## Build the model\n",
    "    # Load the base model\n",
    "    baseModel = VGG16(weights='imagenet', include_top=False, input_shape=(images.shape[1], images.shape[2], 3))\n",
    "    \n",
    "    # Initially freeze all layers of the base model\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build the full model\n",
    "    model = Sequential()\n",
    "    model.add(baseModel)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    ## Step 1: Train only the fully connected layers\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],   \n",
    "                  optimizer=SGD(learning_rate=lr_freeze))\n",
    "\n",
    "    # Train the model\n",
    "    ti = time.time()\n",
    "    history1 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0  # Suppress training output\n",
    "    )\n",
    "\n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history1.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 1 of fine-tuning: {best_auc}')\n",
    "    print()\n",
    "        \n",
    "\n",
    "    ## Step 2: Unfreeze part of the base model\n",
    "    total_layers = len(baseModel.layers)\n",
    "    unfreeze_layers = int(total_layers * perc_unfreeze)\n",
    "\n",
    "    for layer in baseModel.layers[total_layers - unfreeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile the model with a reduced learning rate\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],  \n",
    "                  optimizer=SGD(learning_rate=lr_unfreeze))\n",
    "\n",
    "    # Train the model for fine-tuning\n",
    "    history2 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs-epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0\n",
    "    )\n",
    "        \n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history2.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 2 of fine-tuning: {best_auc}')\n",
    "\n",
    "    train_time = time.time() - ti\n",
    "    hours, remainder = divmod(train_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "    ## Save learning curves\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(epochs), history1.history['loss']+history2.history['loss'], label='Train Loss')\n",
    "    plt.plot(range(epochs), history1.history['val_loss']+history2.history['val_loss'], label='Test Loss')\n",
    "    plt.legend(loc='upper right',fontsize=10)\n",
    "    plt.title('Train and Test Loss',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(epochs), history1.history['accuracy']+history2.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history1.history['val_accuracy']+history2.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test Accuracy',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(epochs), history1.history['AUC']+history2.history['AUC'], label='Train AUC')\n",
    "    plt.plot(range(epochs), history1.history['val_AUC']+history2.history['val_AUC'], label='Test AUC')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test ROC AUC',fontsize=12)\n",
    "    \n",
    "    plt.savefig('Learning_curves/VGG16_'+str(trial+1)+'.png'), plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    ## Save the model\n",
    "    model.save('Models/VGG16_'+str(trial+1)+'.h5')\n",
    "\n",
    "    ## Print the number of parameters in the model\n",
    "    total_params = model.count_params()  # total_params = np.sum([np.prod(v.shape.as_list()) for v in model.variables])\n",
    "    trainable_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_variables])\n",
    "    print(f'Classifier has {total_params} total parameters, {trainable_params} of which are trainable.'), print()\n",
    "\n",
    "    \n",
    "    ## Predict\n",
    "    train_preds = model.predict(images_train)\n",
    "    np.save('Predictions/VGG16_train_'+str(trial+1)+'.npy',train_preds)\n",
    "    test_preds = model.predict(images_test)\n",
    "    np.save('Predictions/VGG16_test_'+str(trial+1)+'.npy',test_preds)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    results_train = evaluate_model(train_preds, train_labels)\n",
    "    print('TRAIN results:')\n",
    "    for metric, value in results_train.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    results_test = evaluate_model(test_preds, test_labels)\n",
    "    print('TEST results:')\n",
    "    for metric, value in results_test.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    ## Store results\n",
    "    trials_results.append(\n",
    "        {'classifier':'VGG16',\n",
    "         'trial':trial+1,\n",
    "         'parameters':trainable_params,\n",
    "         'trainTime':train_time,\n",
    "         **{'train_'+k:v for k,v in results_train.items()},\n",
    "         **{'test_'+k:v for k,v in results_test.items()}\n",
    "        }\n",
    "    )    \n",
    "\n",
    "    ## Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "pd.DataFrame(trials_results).to_csv('CNN_Results_'+str(N)+'trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b221c8ee-53c2-4ff1-8680-291ff9502304",
   "metadata": {},
   "source": [
    "## DenseNet 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713073c0-b75e-45ac-a761-d9d1ec2ca47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c6455-861b-4b4b-9f57-c8ba1346d294",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fc509-7971-4869-87f1-d5da2af07ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter tuning\n",
    "# Objective function for the specific pre-trained CNN\n",
    "objective_pt = lambda params: objective_preTrainedCNN(params, DenseNet121)\n",
    "\n",
    "# Create trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run optimization\n",
    "ti = time.time()\n",
    "best = fmin(\n",
    "    fn=objective_pt,\n",
    "    space=space_preTrainedCNN,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials = trials\n",
    ")\n",
    "tuningTime = time.time() - ti\n",
    "\n",
    "hours, remainder = divmod(tuningTime, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f'Hyperparameter tuning took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "print(\"Best hyperparameters:\", space_eval(space_preTrainedCNN, best))\n",
    "\n",
    "learning_rates_pt['DenseNet121'] = {'lr_freeze' : best['lr_freeze'], 'lr_unfreeze' : best['lr_unfreeze']}\n",
    "\n",
    "# Plot the parameter tuning process\n",
    "lrs_freeze = np.asarray([trial['misc']['vals']['lr_freeze'][0] for trial in trials.trials])\n",
    "lrs_unfreeze = np.asarray([trial['misc']['vals']['lr_unfreeze'][0] for trial in trials.trials])\n",
    "losses = np.asarray([trial['result']['loss'] for trial in trials.trials])\n",
    "    \n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(lrs_freeze, lrs_unfreeze, -losses, c=losses, cmap='viridis', label='Loss vs. Learning Rates')\n",
    "ax.set_xlabel('Learning Rate for Step 1')\n",
    "ax.set_ylabel('Learning Rate for Step 2')\n",
    "ax.set_zlabel('Mean ROC AUC')\n",
    "ax.set_title('Hyperparameter Tuning: ROC AUC vs. Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.savefig('Parameter_tuning/LearningRate_tuning/DenseNet121.png'), plt.show()\n",
    "plt.show()\n",
    "    \n",
    "# Save the results\n",
    "pd.DataFrame(learning_rates_pt).to_csv('Parameters_preTrainedCNNs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7099c40-aba5-48f3-b4bd-68aa6cb8d3e8",
   "metadata": {},
   "source": [
    "### Train N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a84db6-44f3-4bd0-bb58-7cb31df5b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_pt = pd.read_csv('Parameters_preTrainedCNNs.csv', index_col = 0)\n",
    "trials_results = pd.read_csv('CNN_Results_'+str(N)+'trials.csv', index_col = 0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f0b3e-76e5-441e-ab1f-a1e79690d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the splitter to split the dataset into 85% train and 15% tests sets N times \n",
    "splitter = StratifiedShuffleSplit(n_splits=N, test_size=int(round(0.15*len(labels))), random_state = seed)\n",
    "\n",
    "# Get the tuned learning rates\n",
    "lr_freeze = learning_rates_pt['DenseNet121']['lr_freeze']\n",
    "lr_unfreeze = learning_rates_pt['DenseNet121']['lr_unfreeze']\n",
    "    \n",
    "for trial, (train_index, test_index) in enumerate(splitter.split(front, labels)):\n",
    "        \n",
    "    print(f'Trial {trial + 1}'), print()\n",
    "\n",
    "    ## Split the dataset into train (85%) and test (15%) sets\n",
    "    train_front = front[train_index]\n",
    "    train_L90 = L90[train_index]\n",
    "    train_R90 = R90[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "        \n",
    "    test_front = front[test_index]\n",
    "    test_L90 = L90[test_index]\n",
    "    test_R90 = R90[test_index]\n",
    "    test_labels = labels[test_index]\n",
    "    \n",
    "    ## Stack views along the channel dimension\n",
    "    images_train = np.stack((train_front[:,:,:,0], train_L90[:,:,:,0], train_R90[:,:,:,0]), axis=-1)\n",
    "    images_test = np.stack((test_front[:,:,:,0], test_L90[:,:,:,0], test_R90[:,:,:,0]), axis=-1)\n",
    "    \n",
    "    ## Calculate the weight for training to address class imbalance\n",
    "    rate_train = sum(train_labels == 0) / sum(train_labels)\n",
    "    \n",
    "    ## Build the model\n",
    "    # Load the base model\n",
    "    baseModel = DenseNet121(weights='imagenet', include_top=False, input_shape=(images.shape[1], images.shape[2], 3))\n",
    "    \n",
    "    # Initially freeze all layers of the base model\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build the full model\n",
    "    model = Sequential()\n",
    "    model.add(baseModel)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    ## Step 1: Train only the fully connected layers\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],\n",
    "                  optimizer=SGD(learning_rate=lr_freeze))\n",
    "\n",
    "    # Train the model\n",
    "    ti = time.time()\n",
    "    history1 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0  # Suppress training output\n",
    "    )\n",
    "\n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history1.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 1 of fine-tuning: {best_auc}')\n",
    "    print()\n",
    "        \n",
    "\n",
    "    ## Step 2: Unfreeze part of the base model\n",
    "    total_layers = len(baseModel.layers)\n",
    "    unfreeze_layers = int(total_layers * perc_unfreeze)\n",
    "\n",
    "    for layer in baseModel.layers[total_layers - unfreeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile the model with a reduced learning rate\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],   \n",
    "                  optimizer=SGD(learning_rate=lr_unfreeze))\n",
    "\n",
    "    # Train the model for fine-tuning\n",
    "    history2 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs-epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0\n",
    "    )\n",
    "        \n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history2.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 2 of fine-tuning: {best_auc}')\n",
    "\n",
    "    train_time = time.time() - ti\n",
    "    hours, remainder = divmod(train_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "    ## Save learning curves\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(epochs), history1.history['loss']+history2.history['loss'], label='Train Loss')\n",
    "    plt.plot(range(epochs), history1.history['val_loss']+history2.history['val_loss'], label='Test Loss')\n",
    "    plt.legend(loc='upper right',fontsize=10)\n",
    "    plt.title('Train and Test Loss',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(epochs), history1.history['accuracy']+history2.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history1.history['val_accuracy']+history2.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test Accuracy',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(epochs), history1.history['AUC']+history2.history['AUC'], label='Train AUC')\n",
    "    plt.plot(range(epochs), history1.history['val_AUC']+history2.history['val_AUC'], label='Test AUC')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test ROC AUC',fontsize=12)\n",
    "    \n",
    "    plt.savefig('Learning_curves/DenseNet121_'+str(trial+1)+'.png'), plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    ## Save the model\n",
    "    model.save('Models/DenseNet121_'+str(trial+1)+'.h5')\n",
    "\n",
    "    ## Print the number of parameters in the model\n",
    "    total_params = model.count_params()  # total_params = np.sum([np.prod(v.shape.as_list()) for v in model.variables])\n",
    "    trainable_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_variables])\n",
    "    print(f'Classifier has {total_params} total parameters, {trainable_params} of which are trainable.'), print()\n",
    "\n",
    "    \n",
    "    ## Predict\n",
    "    train_preds = model.predict(images_train)\n",
    "    np.save('Predictions/DenseNet121_train_'+str(trial+1)+'.npy',train_preds)\n",
    "    test_preds = model.predict(images_test)\n",
    "    np.save('Predictions/DenseNet121_test_'+str(trial+1)+'.npy',test_preds)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    results_train = evaluate_model(train_preds, train_labels)\n",
    "    print('TRAIN results:')\n",
    "    for metric, value in results_train.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    results_test = evaluate_model(test_preds, test_labels)\n",
    "    print('TEST results:')\n",
    "    for metric, value in results_test.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    ## Store results\n",
    "    trials_results.append(\n",
    "        {'classifier':'DenseNet121',\n",
    "         'trial':trial+1,\n",
    "         'parameters':trainable_params,\n",
    "         'trainTime':train_time,\n",
    "         **{'train_'+k:v for k,v in results_train.items()},\n",
    "         **{'test_'+k:v for k,v in results_test.items()}\n",
    "        }\n",
    "    )    \n",
    "\n",
    "    ## Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "pd.DataFrame(trials_results).to_csv('CNN_Results_'+str(N)+'trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a66b5a-f100-46a4-87bd-84aede7cb331",
   "metadata": {},
   "source": [
    "## ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffde36d-7c2c-47bc-96fa-1327b81c20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc43bb-dc48-4e20-af3c-cc677e3eae60",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40c70d-67ac-473f-8a38-bfe5026ee42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter tuning\n",
    "# Objective function for the specific pre-trained CNN\n",
    "objective_pt = lambda params: objective_preTrainedCNN(params, ResNet50)\n",
    "\n",
    "# Create trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run optimization\n",
    "ti = time.time()\n",
    "best = fmin(\n",
    "    fn=objective_pt,\n",
    "    space=space_preTrainedCNN,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials = trials\n",
    ")\n",
    "tuningTime = time.time() - ti\n",
    "\n",
    "hours, remainder = divmod(tuningTime, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f'Hyperparameter tuning took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "print(\"Best hyperparameters:\", space_eval(space_preTrainedCNN, best))\n",
    "\n",
    "learning_rates_pt['ResNet50'] = {'lr_freeze' : best['lr_freeze'], 'lr_unfreeze' : best['lr_unfreeze']}\n",
    "\n",
    "# Plot the parameter tuning process\n",
    "lrs_freeze = np.asarray([trial['misc']['vals']['lr_freeze'][0] for trial in trials.trials])\n",
    "lrs_unfreeze = np.asarray([trial['misc']['vals']['lr_unfreeze'][0] for trial in trials.trials])\n",
    "losses = np.asarray([trial['result']['loss'] for trial in trials.trials])\n",
    "    \n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(lrs_freeze, lrs_unfreeze, -losses, c=losses, cmap='viridis', label='Loss vs. Learning Rates')\n",
    "ax.set_xlabel('Learning Rate for Step 1')\n",
    "ax.set_ylabel('Learning Rate for Step 2')\n",
    "ax.set_zlabel('Mean ROC AUC')\n",
    "ax.set_title('Hyperparameter Tuning: ROC AUC vs. Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.savefig('Parameter_tuning/LearningRate_tuning/ResNet50.png'), plt.show()\n",
    "plt.show()\n",
    "    \n",
    "# Save the results\n",
    "pd.DataFrame(learning_rates_pt).to_csv('Parameters_preTrainedCNNs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171b997-81dd-46c2-b5af-4f12d5dcf1fa",
   "metadata": {},
   "source": [
    "### Train N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d1aa3-50fb-4f66-9c91-2aa913faf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_pt = pd.read_csv('Parameters_preTrainedCNNs.csv', index_col = 0)\n",
    "trials_results = pd.read_csv('CNN_Results_'+str(N)+'trials.csv', index_col = 0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01842db-99f7-4fcb-8c5d-21ae3f0e5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the splitter to split the dataset into 85% train and 15% tests sets N times \n",
    "splitter = StratifiedShuffleSplit(n_splits=N, test_size=int(round(0.15*len(labels))), random_state = seed)\n",
    "\n",
    "# Get the tuned learning rates\n",
    "lr_freeze = learning_rates_pt['ResNet50']['lr_freeze']\n",
    "lr_unfreeze = learning_rates_pt['ResNet50']['lr_unfreeze']\n",
    "    \n",
    "for trial, (train_index, test_index) in enumerate(splitter.split(front, labels)):\n",
    "        \n",
    "    print(f'Trial {trial + 1}'), print()\n",
    "\n",
    "    ## Split the dataset into train (85%) and test (15%) sets\n",
    "    train_front = front[train_index]\n",
    "    train_L90 = L90[train_index]\n",
    "    train_R90 = R90[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "        \n",
    "    test_front = front[test_index]\n",
    "    test_L90 = L90[test_index]\n",
    "    test_R90 = R90[test_index]\n",
    "    test_labels = labels[test_index]\n",
    "    \n",
    "    ## Stack views along the channel dimension\n",
    "    images_train = np.stack((train_front[:,:,:,0], train_L90[:,:,:,0], train_R90[:,:,:,0]), axis=-1)\n",
    "    images_test = np.stack((test_front[:,:,:,0], test_L90[:,:,:,0], test_R90[:,:,:,0]), axis=-1)\n",
    "    \n",
    "    ## Calculate the weight for training to address class imbalance\n",
    "    rate_train = sum(train_labels == 0) / sum(train_labels)\n",
    "    \n",
    "    ## Build the model\n",
    "    # Load the base model\n",
    "    baseModel = ResNet50(weights='imagenet', include_top=False, input_shape=(images.shape[1], images.shape[2], 3))\n",
    "    \n",
    "    # Initially freeze all layers of the base model\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build the full model\n",
    "    model = Sequential()\n",
    "    model.add(baseModel)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    ## Step 1: Train only the fully connected layers\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],\n",
    "                  optimizer=SGD(learning_rate=lr_freeze))\n",
    "\n",
    "    # Train the model\n",
    "    ti = time.time()\n",
    "    history1 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0  # Suppress training output\n",
    "    )\n",
    "\n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history1.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 1 of fine-tuning: {best_auc}')\n",
    "    print()\n",
    "        \n",
    "\n",
    "    ## Step 2: Unfreeze part of the base model\n",
    "    total_layers = len(baseModel.layers)\n",
    "    unfreeze_layers = int(total_layers * perc_unfreeze)\n",
    "\n",
    "    for layer in baseModel.layers[total_layers - unfreeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile the model with a reduced learning rate\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],\n",
    "                  optimizer=SGD(learning_rate=lr_unfreeze))\n",
    "\n",
    "    # Train the model for fine-tuning\n",
    "    history2 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs-epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0\n",
    "    )\n",
    "        \n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history2.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 2 of fine-tuning: {best_auc}')\n",
    "\n",
    "    train_time = time.time() - ti\n",
    "    hours, remainder = divmod(train_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "    ## Save learning curves\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(epochs), history1.history['loss']+history2.history['loss'], label='Train Loss')\n",
    "    plt.plot(range(epochs), history1.history['val_loss']+history2.history['val_loss'], label='Test Loss')\n",
    "    plt.legend(loc='upper right',fontsize=10)\n",
    "    plt.title('Train and Test Loss',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(epochs), history1.history['accuracy']+history2.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history1.history['val_accuracy']+history2.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test Accuracy',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(epochs), history1.history['AUC']+history2.history['AUC'], label='Train AUC')\n",
    "    plt.plot(range(epochs), history1.history['val_AUC']+history2.history['val_AUC'], label='Test AUC')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test ROC AUC',fontsize=12)\n",
    "    \n",
    "    plt.savefig('Learning_curves/ResNet50_'+str(trial+1)+'.png'), plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    ## Save the model\n",
    "    model.save('Models/ResNet50_'+str(trial+1)+'.h5')\n",
    "\n",
    "    ## Print the number of parameters in the model\n",
    "    total_params = model.count_params()  # total_params = np.sum([np.prod(v.shape.as_list()) for v in model.variables])\n",
    "    trainable_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_variables])\n",
    "    print(f'Classifier has {total_params} total parameters, {trainable_params} of which are trainable.'), print()\n",
    "\n",
    "    \n",
    "    ## Predict\n",
    "    train_preds = model.predict(images_train)\n",
    "    np.save('Predictions/ResNet50_train_'+str(trial+1)+'.npy',train_preds)\n",
    "    test_preds = model.predict(images_test)\n",
    "    np.save('Predictions/ResNet50_test_'+str(trial+1)+'.npy',test_preds)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    results_train = evaluate_model(train_preds, train_labels)\n",
    "    print('TRAIN results:')\n",
    "    for metric, value in results_train.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    results_test = evaluate_model(test_preds, test_labels)\n",
    "    print('TEST results:')\n",
    "    for metric, value in results_test.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    ## Store results\n",
    "    trials_results.append(\n",
    "        {'classifier':'ResNet50',\n",
    "         'trial':trial+1,\n",
    "         'parameters':trainable_params,\n",
    "         'trainTime':train_time,\n",
    "         **{'train_'+k:v for k,v in results_train.items()},\n",
    "         **{'test_'+k:v for k,v in results_test.items()}\n",
    "        }\n",
    "    )    \n",
    "\n",
    "    ## Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "pd.DataFrame(trials_results).to_csv('CNN_Results_'+str(N)+'trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe0248-b22b-41e5-8616-207f54ad2215",
   "metadata": {},
   "source": [
    "## MobileNet V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db06cbc-e95b-40b4-affe-b8ab5179b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8fa0e7-05db-44b9-a5ea-c0b7768b22ca",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c329f-663b-4320-892a-e7e54d387ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter tuning\n",
    "# Objective function for the specific pre-trained CNN\n",
    "objective_pt = lambda params: objective_preTrainedCNN(params, MobileNet)\n",
    "\n",
    "# Create trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run optimization\n",
    "ti = time.time()\n",
    "best = fmin(\n",
    "    fn=objective_pt,\n",
    "    space=space_preTrainedCNN,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials = trials\n",
    ")\n",
    "tuningTime = time.time() - ti\n",
    "\n",
    "hours, remainder = divmod(tuningTime, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f'Hyperparameter tuning took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "print(\"Best hyperparameters:\", space_eval(space_preTrainedCNN, best))\n",
    "\n",
    "learning_rates_pt['MobileNet'] = {'lr_freeze' : best['lr_freeze'], 'lr_unfreeze' : best['lr_unfreeze']}\n",
    "\n",
    "# Plot the parameter tuning process\n",
    "lrs_freeze = np.asarray([trial['misc']['vals']['lr_freeze'][0] for trial in trials.trials])\n",
    "lrs_unfreeze = np.asarray([trial['misc']['vals']['lr_unfreeze'][0] for trial in trials.trials])\n",
    "losses = np.asarray([trial['result']['loss'] for trial in trials.trials])\n",
    "    \n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(lrs_freeze, lrs_unfreeze, -losses, c=losses, cmap='viridis', label='Loss vs. Learning Rates')\n",
    "ax.set_xlabel('Learning Rate for Step 1')\n",
    "ax.set_ylabel('Learning Rate for Step 2')\n",
    "ax.set_zlabel('Mean ROC AUC')\n",
    "ax.set_title('Hyperparameter Tuning: ROC AUC vs. Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.savefig('Parameter_tuning/LearningRate_tuning/MobileNet.png'), plt.show()\n",
    "plt.show()\n",
    "    \n",
    "# Save the results\n",
    "pd.DataFrame(learning_rates_pt).to_csv('Parameters_preTrainedCNNs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f37414-1dd1-471f-9a9d-a0f51b75d23e",
   "metadata": {},
   "source": [
    "### Train N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2954be1-72bb-4d2d-aaf0-2b81dff3f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_pt = pd.read_csv('Parameters_preTrainedCNNs.csv', index_col = 0)\n",
    "trials_results = pd.read_csv('CNN_Results_'+str(N)+'trials.csv', index_col = 0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d771c-6f7a-4616-9e8a-aa22b60be7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the splitter to split the dataset into 85% train and 15% tests sets N times \n",
    "splitter = StratifiedShuffleSplit(n_splits=N, test_size=int(round(0.15*len(labels))), random_state = seed)\n",
    "\n",
    "# Get the tuned learning rates\n",
    "lr_freeze = learning_rates_pt['MobileNet']['lr_freeze']\n",
    "lr_unfreeze = learning_rates_pt['MobileNet']['lr_unfreeze']\n",
    "    \n",
    "for trial, (train_index, test_index) in enumerate(splitter.split(front, labels)):\n",
    "        \n",
    "    print(f'Trial {trial + 1}'), print()\n",
    "\n",
    "    ## Split the dataset into train (85%) and test (15%) sets\n",
    "    train_front = front[train_index]\n",
    "    train_L90 = L90[train_index]\n",
    "    train_R90 = R90[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "        \n",
    "    test_front = front[test_index]\n",
    "    test_L90 = L90[test_index]\n",
    "    test_R90 = R90[test_index]\n",
    "    test_labels = labels[test_index]\n",
    "    \n",
    "    ## Stack views along the channel dimension\n",
    "    images_train = np.stack((train_front[:,:,:,0], train_L90[:,:,:,0], train_R90[:,:,:,0]), axis=-1)\n",
    "    images_test = np.stack((test_front[:,:,:,0], test_L90[:,:,:,0], test_R90[:,:,:,0]), axis=-1)\n",
    "    \n",
    "    ## Calculate the weight for training to address class imbalance\n",
    "    rate_train = sum(train_labels == 0) / sum(train_labels)\n",
    "    \n",
    "    ## Build the model\n",
    "    # Load the base model\n",
    "    baseModel = MobileNet(weights='imagenet', include_top=False, input_shape=(images.shape[1], images.shape[2], 3))\n",
    "    \n",
    "    # Initially freeze all layers of the base model\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build the full model\n",
    "    model = Sequential()\n",
    "    model.add(baseModel)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    ## Step 1: Train only the fully connected layers\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error], \n",
    "                  optimizer=SGD(learning_rate=lr_freeze))\n",
    "\n",
    "    # Train the model\n",
    "    ti = time.time()\n",
    "    history1 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0  # Suppress training output\n",
    "    )\n",
    "\n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history1.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 1 of fine-tuning: {best_auc}')\n",
    "    print()\n",
    "        \n",
    "\n",
    "    ## Step 2: Unfreeze part of the base model\n",
    "    total_layers = len(baseModel.layers)\n",
    "    unfreeze_layers = int(total_layers * perc_unfreeze)\n",
    "\n",
    "    for layer in baseModel.layers[total_layers - unfreeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile the model with a reduced learning rate\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],  \n",
    "                  optimizer=SGD(learning_rate=lr_unfreeze))\n",
    "\n",
    "    # Train the model for fine-tuning\n",
    "    history2 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs-epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0\n",
    "    )\n",
    "        \n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history2.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 2 of fine-tuning: {best_auc}')\n",
    "\n",
    "    train_time = time.time() - ti\n",
    "    hours, remainder = divmod(train_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "    ## Save learning curves\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(epochs), history1.history['loss']+history2.history['loss'], label='Train Loss')\n",
    "    plt.plot(range(epochs), history1.history['val_loss']+history2.history['val_loss'], label='Test Loss')\n",
    "    plt.legend(loc='upper right',fontsize=10)\n",
    "    plt.title('Train and Test Loss',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(epochs), history1.history['accuracy']+history2.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history1.history['val_accuracy']+history2.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test Accuracy',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(epochs), history1.history['AUC']+history2.history['AUC'], label='Train AUC')\n",
    "    plt.plot(range(epochs), history1.history['val_AUC']+history2.history['val_AUC'], label='Test AUC')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test ROC AUC',fontsize=12)\n",
    "    \n",
    "    plt.savefig('Learning_curves/MobileNet_'+str(trial+1)+'.png'), plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    ## Save the model\n",
    "    model.save('Models/MobileNet_'+str(trial+1)+'.h5')\n",
    "\n",
    "    ## Print the number of parameters in the model\n",
    "    total_params = model.count_params()  # total_params = np.sum([np.prod(v.shape.as_list()) for v in model.variables])\n",
    "    trainable_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_variables])\n",
    "    print(f'Classifier has {total_params} total parameters, {trainable_params} of which are trainable.'), print()\n",
    "\n",
    "    \n",
    "    ## Predict\n",
    "    train_preds = model.predict(images_train)\n",
    "    np.save('Predictions/MobileNet_train_'+str(trial+1)+'.npy',train_preds)\n",
    "    test_preds = model.predict(images_test)\n",
    "    np.save('Predictions/MobileNet_test_'+str(trial+1)+'.npy',test_preds)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    results_train = evaluate_model(train_preds, train_labels)\n",
    "    print('TRAIN results:')\n",
    "    for metric, value in results_train.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    results_test = evaluate_model(test_preds, test_labels)\n",
    "    print('TEST results:')\n",
    "    for metric, value in results_test.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    ## Store results\n",
    "    trials_results.append(\n",
    "        {'classifier':'MobileNet',\n",
    "         'trial':trial+1,\n",
    "         'parameters':trainable_params,\n",
    "         'trainTime':train_time,\n",
    "         **{'train_'+k:v for k,v in results_train.items()},\n",
    "         **{'test_'+k:v for k,v in results_test.items()}\n",
    "        }\n",
    "    )    \n",
    "\n",
    "    ## Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "pd.DataFrame(trials_results).to_csv('CNN_Results_'+str(N)+'trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e877a-aaab-4181-ac93-8fe80ac4a270",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a55583-3c19-4195-8901-0b0e9cdc7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d780eb7c-a4c0-452b-8a1c-f482ac141db0",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7313b-acbd-4190-8dff-4a2b4693aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter tuning\n",
    "# Objective function for the specific pre-trained CNN\n",
    "objective_pt = lambda params: objective_preTrainedCNN(params, InceptionV3)\n",
    "\n",
    "# Create trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run optimization\n",
    "ti = time.time()\n",
    "best = fmin(\n",
    "    fn=objective_pt,\n",
    "    space=space_preTrainedCNN,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials = trials\n",
    ")\n",
    "tuningTime = time.time() - ti\n",
    "\n",
    "hours, remainder = divmod(tuningTime, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f'Hyperparameter tuning took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "print(\"Best hyperparameters:\", space_eval(space_preTrainedCNN, best))\n",
    "\n",
    "learning_rates_pt['InceptionV3'] = {'lr_freeze' : best['lr_freeze'], 'lr_unfreeze' : best['lr_unfreeze']}\n",
    "\n",
    "# Plot the parameter tuning process\n",
    "lrs_freeze = np.asarray([trial['misc']['vals']['lr_freeze'][0] for trial in trials.trials])\n",
    "lrs_unfreeze = np.asarray([trial['misc']['vals']['lr_unfreeze'][0] for trial in trials.trials])\n",
    "losses = np.asarray([trial['result']['loss'] for trial in trials.trials])\n",
    "    \n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(lrs_freeze, lrs_unfreeze, -losses, c=losses, cmap='viridis', label='Loss vs. Learning Rates')\n",
    "ax.set_xlabel('Learning Rate for Step 1')\n",
    "ax.set_ylabel('Learning Rate for Step 2')\n",
    "ax.set_zlabel('Mean ROC AUC')\n",
    "ax.set_title('Hyperparameter Tuning: ROC AUC vs. Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.savefig('Parameter_tuning/LearningRate_tuning/InceptionV3.png'), plt.show()\n",
    "plt.show()\n",
    "    \n",
    "# Save the results\n",
    "pd.DataFrame(learning_rates_pt).to_csv('Parameters_preTrainedCNNs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164026be-0166-45e9-8788-4ee2856e8f7d",
   "metadata": {},
   "source": [
    "### Train N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9761f28-1b3a-4857-8843-333423860150",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_pt = pd.read_csv('Parameters_preTrainedCNNs.csv', index_col = 0)\n",
    "trials_results = pd.read_csv('CNN_Results_'+str(N)+'trials.csv', index_col = 0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53811a61-9c3f-48fc-aea3-a5f59832b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the splitter to split the dataset into 85% train and 15% tests sets N times \n",
    "splitter = StratifiedShuffleSplit(n_splits=N, test_size=int(round(0.15*len(labels))), random_state = seed)\n",
    "\n",
    "# Get the tuned learning rates\n",
    "lr_freeze = learning_rates_pt['InceptionV3']['lr_freeze']\n",
    "lr_unfreeze = learning_rates_pt['InceptionV3']['lr_unfreeze']\n",
    "    \n",
    "for trial, (train_index, test_index) in enumerate(splitter.split(front, labels)):\n",
    "        \n",
    "    print(f'Trial {trial + 1}'), print()\n",
    "\n",
    "    ## Split the dataset into train (85%) and test (15%) sets\n",
    "    train_front = front[train_index]\n",
    "    train_L90 = L90[train_index]\n",
    "    train_R90 = R90[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "        \n",
    "    test_front = front[test_index]\n",
    "    test_L90 = L90[test_index]\n",
    "    test_R90 = R90[test_index]\n",
    "    test_labels = labels[test_index]\n",
    "    \n",
    "    ## Stack views along the channel dimension\n",
    "    images_train = np.stack((train_front[:,:,:,0], train_L90[:,:,:,0], train_R90[:,:,:,0]), axis=-1)\n",
    "    images_test = np.stack((test_front[:,:,:,0], test_L90[:,:,:,0], test_R90[:,:,:,0]), axis=-1)\n",
    "    \n",
    "    ## Calculate the weight for training to address class imbalance\n",
    "    rate_train = sum(train_labels == 0) / sum(train_labels)\n",
    "    \n",
    "    ## Build the model\n",
    "    # Load the base model\n",
    "    baseModel = InceptionV3(weights='imagenet', include_top=False, input_shape=(images.shape[1], images.shape[2], 3))\n",
    "    \n",
    "    # Initially freeze all layers of the base model\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build the full model\n",
    "    model = Sequential()\n",
    "    model.add(baseModel)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    ## Step 1: Train only the fully connected layers\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],\n",
    "                  optimizer=SGD(learning_rate=lr_freeze))\n",
    "\n",
    "    # Train the model\n",
    "    ti = time.time()\n",
    "    history1 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0  # Suppress training output\n",
    "    )\n",
    "\n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history1.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 1 of fine-tuning: {best_auc}')\n",
    "    print()\n",
    "        \n",
    "\n",
    "    ## Step 2: Unfreeze part of the base model\n",
    "    total_layers = len(baseModel.layers)\n",
    "    unfreeze_layers = int(total_layers * perc_unfreeze)\n",
    "\n",
    "    for layer in baseModel.layers[total_layers - unfreeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile the model with a reduced learning rate\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC', 'TruePositives', 'FalseNegatives', 'TrueNegatives', 'FalsePositives', 'Precision', 'Recall', weighted_error],  \n",
    "                  optimizer=SGD(learning_rate=lr_unfreeze))\n",
    "\n",
    "    # Train the model for fine-tuning\n",
    "    history2 = model.fit(\n",
    "        train_images, train_labels,\n",
    "        class_weight={0: 1, 1: rate_train},\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs-epochs_freeze,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[NaNCheckCallback()],\n",
    "        verbose=0\n",
    "    )\n",
    "        \n",
    "    # Print the best validation AUC for in this step\n",
    "    best_auc = max(history2.history['val_AUC'])\n",
    "    print(f'Max test ROC AUC after step 2 of fine-tuning: {best_auc}')\n",
    "\n",
    "    train_time = time.time() - ti\n",
    "    hours, remainder = divmod(train_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training took {hours} hours, {minutes} minutes, and {seconds} seconds.')\n",
    "\n",
    "    ## Save learning curves\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(epochs), history1.history['loss']+history2.history['loss'], label='Train Loss')\n",
    "    plt.plot(range(epochs), history1.history['val_loss']+history2.history['val_loss'], label='Test Loss')\n",
    "    plt.legend(loc='upper right',fontsize=10)\n",
    "    plt.title('Train and Test Loss',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(epochs), history1.history['accuracy']+history2.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(range(epochs), history1.history['val_accuracy']+history2.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test Accuracy',fontsize=12)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(epochs), history1.history['AUC']+history2.history['AUC'], label='Train AUC')\n",
    "    plt.plot(range(epochs), history1.history['val_AUC']+history2.history['val_AUC'], label='Test AUC')\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.title('Train and Test ROC AUC',fontsize=12)\n",
    "    \n",
    "    plt.savefig('Learning_curves/InceptionV3_'+str(trial+1)+'.png'), plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    ## Save the model\n",
    "    model.save('Models/InceptionV3_'+str(trial+1)+'.h5')\n",
    "\n",
    "    ## Print the number of parameters in the model\n",
    "    total_params = model.count_params()  # total_params = np.sum([np.prod(v.shape.as_list()) for v in model.variables])\n",
    "    trainable_params = np.sum([np.prod(v.shape.as_list()) for v in model.trainable_variables])\n",
    "    print(f'Classifier has {total_params} total parameters, {trainable_params} of which are trainable.'), print()\n",
    "\n",
    "    \n",
    "    ## Predict\n",
    "    train_preds = model.predict(images_train)\n",
    "    np.save('Predictions/InceptionV3_train_'+str(trial+1)+'.npy',train_preds)\n",
    "    test_preds = model.predict(images_test)\n",
    "    np.save('Predictions/InceptionV3_test_'+str(trial+1)+'.npy',test_preds)\n",
    "\n",
    "    ## Evaluate the model\n",
    "    results_train = evaluate_model(train_preds, train_labels)\n",
    "    print('TRAIN results:')\n",
    "    for metric, value in results_train.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    results_test = evaluate_model(test_preds, test_labels)\n",
    "    print('TEST results:')\n",
    "    for metric, value in results_test.items():\n",
    "        print(f'{metric}: {value:.4f}' if isinstance(value, (float, int)) else f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "    ## Store results\n",
    "    trials_results.append(\n",
    "        {'classifier':'InceptionV3',\n",
    "         'trial':trial+1,\n",
    "         'parameters':trainable_params,\n",
    "         'trainTime':train_time,\n",
    "         **{'train_'+k:v for k,v in results_train.items()},\n",
    "         **{'test_'+k:v for k,v in results_test.items()}\n",
    "        }\n",
    "    )    \n",
    "\n",
    "    ## Clear TensorFlow session to release GPU memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "pd.DataFrame(trials_results).to_csv('CNN_Results_'+str(N)+'trials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf44dd-6f4e-4904-883c-df04e493a5c9",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc26489d-f959-40c8-a71a-22fd72388fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = pd.read_csv('CNN_Results_'+str(N)+'trials.csv', index_col = 0)\n",
    "trials_results.fillna(1e-10, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00abfa5-6466-46b8-b2a6-072fd802e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print statistics\n",
    "models = trials_results.classifier.unique()\n",
    "metrics = [c for c in trials_results.columns if 'test_' in c and c not in ['test_TP','test_FP','test_TN','test_FN']]\n",
    "    \n",
    "statistics = pd.DataFrame(index=models, columns=[item for sublist in [[metric+'_mean', metric+'_std'] for metric in metrics] for item in sublist])\n",
    "    \n",
    "for metric in metrics:\n",
    "    mn, st = metric+'_mean', metric+'_std'\n",
    "    for model in models:\n",
    "        results = trials_results[trials_results['classifier']==model][metric].values\n",
    "        statistics.at[model,mn] = results.mean()\n",
    "        statistics.at[model,st] = results.std()\n",
    "\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e807eb-80bf-4d9b-8819-d8e4d4dd7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [m for m in metrics if 'test' in m]:\n",
    "    mn, st = metric+'_mean', metric+'_std'\n",
    "    if 'Loss' in metric or 'WE' in metric:\n",
    "        model_best = pd.to_numeric(statistics[metric+'_mean']).idxmin()\n",
    "        print(f'Model with lowest {metric} is {model_best} with value {statistics.loc[model_best,mn]} and standard deviation {statistics.loc[model_best,st]}')\n",
    "    else:\n",
    "        model_best = pd.to_numeric(statistics[metric+'_mean']).idxmax()\n",
    "        print(f'Model with highest {metric} is {model_best} with value {statistics.loc[model_best,mn]} and standard deviation {statistics.loc[model_best,st]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb9033-f958-4fb6-8f00-ba14add0f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print mean and std metrics for each model\n",
    "for classifier_type in trials_results.classifier.unique():\n",
    "    print(f'Classifier: {classifier_type}')\n",
    "    results = trials_results[trials_results['classifier'] == classifier_type]\n",
    "\n",
    "    # Number of parameters\n",
    "    parameters = results['parameters'].values\n",
    "    print(f'Mean number of parameters: {parameters.mean()} [{parameters.min()}, {parameters.max()}], std {parameters.std()}')\n",
    "\n",
    "    # training time\n",
    "    trainTime = results['trainTime'].values\n",
    "    hours, remainder = divmod(trainTime.mean(), 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Mean training time: {hours} hours, {minutes} minutes, and {seconds} seconds, (std {trainTime.std()} sec)')\n",
    "    print()\n",
    "    \n",
    "    # TRAIN results\n",
    "    metrics = ['BCELoss','Accuracy','Sensitivity','Specificity','ROC_AUC','Precision','F1','WE']\n",
    "    for metric in metrics:\n",
    "        values = results['train_' + metric].values\n",
    "        print(f'Mean train {metric}: {values.mean()}, std {values.std()}')\n",
    "    print()\n",
    "\n",
    "    # TEST results\n",
    "    for metric in metrics:\n",
    "        values = results['test_' + metric].values\n",
    "        print(f'Mean test {metric}: {values.mean()}, std {values.std()}')\n",
    "    print()\n",
    "\n",
    "    print('-'*120), print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd5f88-6f39-45df-aa41-a34bb9af2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show boxplots\n",
    "compared_metrics = ['test_BCELoss','test_Accuracy','test_F1','test_ROC_AUC','test_WE'] \n",
    "M = len(compared_metrics)\n",
    "R = M//2 + int(M % 2 > 0)\n",
    "plt.figure(figsize=(5*R, 20))\n",
    "for i,metric in enumerate(compared_metrics):\n",
    "    plt.subplot(R,2,i+1)\n",
    "    sns.boxplot(x='classifier', y=metric, data=trials_results, palette='Set2')\n",
    "    plt.xticks(rotation=25, ha='right')  # Rotate labels 25 degrees\n",
    "    plt.grid(axis='y')\n",
    "    plt.xlabel('')\n",
    "    if 'Loss' in metric or 'WE' in metric:\n",
    "        plt.ylim([0,trials_results[metric].values.max()+0.05*trials_results[metric].values.max()])\n",
    "    else:\n",
    "        plt.ylim([0,1])\n",
    "    plt.title(metric, fontsize=16)\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "plt.savefig('CNN_Boxplots_allModels.png')\n",
    "plt.subplots_adjust(hspace=0.3)  # Increase hspace for more vertical spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e966ac-e4c2-48c7-a7fa-f5f09d7539c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical model comparison\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import probplot\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "    \n",
    "models = trials_results.classifier.unique()\n",
    "compared_metrics = ['test_BCELoss','test_Accuracy','test_F1','test_ROC_AUC','test_WE']\n",
    "    \n",
    "## 1. Select independent metrics\n",
    "#These should be independent. Use the correlation to find dependent variables to remove, if necessary \n",
    "print('Check that the metrics are independent:')\n",
    "print(trials_results[compared_metrics].corr()), print()  # Check for multicollinearity using the correlation matrix\n",
    "\n",
    "var = trials_results[compared_metrics].var().to_numpy()\n",
    "compared_metrics = [metric for metric,v in zip(compared_metrics,var) if not v == 0]  # Remove metrics with zero variance across repetitions\n",
    "\n",
    "## 2. Check for Normality\n",
    "normality = np.ones(len(compared_metrics))\n",
    "L = len(models)//5 + (len(models) % 5 > 0)\n",
    "for i,metric in enumerate(compared_metrics): \n",
    "    print(metric)\n",
    "    ## Check for normality\n",
    "    plt.figure(figsize=(20,2*L))\n",
    "    for j,model in enumerate(models):\n",
    "        # Shapiro-Wilk test\n",
    "        stat, p_value = shapiro(trials_results[trials_results['classifier']==model][metric])\n",
    "        print(f'{model}: Shapiro-Wilk p-value={p_value}')\n",
    "        # If p-value < 0.05, reject normality (non-normal distribution)\n",
    "        normality[i] *= int(p_value > 0.05)\n",
    "\n",
    "        # Generate Q-Q plots to visually inspect normality \n",
    "        plt.subplot(L,5,j+1)\n",
    "        probplot(trials_results[trials_results['classifier']==model][metric], dist='norm', plot=plt)\n",
    "        plt.title(model)\n",
    "    plt.show()\n",
    "    print(f'\\nNormality test for {metric}: {bool(normality[i])}')\n",
    "    print(100*'-')\n",
    "print(), print()\n",
    "    \n",
    "    \n",
    "## 3. Statistical test: MANOVA\n",
    "dependent_variables = ' + '.join(compared_metrics)\n",
    "formula = f'{dependent_variables} ~ classifier'\n",
    "manova = MANOVA.from_formula(formula, data=trials_results)\n",
    "manova_test = manova.mv_test()\n",
    "print(manova_test)\n",
    "\n",
    "## 4. Post-hoc test: Tukey's HSD\n",
    "if manova_test.results['classifier']['stat']['Pr > F']['Pillai\\'s trace'] < 0.05:\n",
    "    for metric in compared_metrics:\n",
    "        print(metric)\n",
    "        tukey = pairwise_tukeyhsd(trials_results[metric],   # Metric data\n",
    "                                          trials_results['classifier'],   # Grouping variable (model)\n",
    "                                          alpha=0.05)   # Significance level\n",
    "        print(tukey)\n",
    "else:\n",
    "    print(f\"MANOVA is not significant, no need to apply Tukey's test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6cf28-d935-447a-8bf4-4f5ce9b3ff48",
   "metadata": {},
   "source": [
    "# Selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc350dc-772c-44cd-a01c-6c4322d55825",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'MultiInputCNN'\n",
    "results_selected = trials_results[trials_results['classifier']==selected_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c39d3a-5816-4f54-8cd3-b908f2b933f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show boxplots\n",
    "df_long = pd.melt(results_selected[compared_metrics], value_vars=compared_metrics, var_name='metric', value_name='value')\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(y='value',x='metric',data=df_long, palette='Set2', fliersize=5)\n",
    "new_labels = [l.replace('test_','') for l in compared_metrics]\n",
    "plt.xticks(ticks=range(len(new_labels)), labels=new_labels, fontsize=18, rotation=25, ha='right')\n",
    "plt.yticks(fontsize=18)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('', fontsize=18)\n",
    "plt.ylabel('', fontsize=18)\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.savefig('CNN_Boxplot_'+selected_model+'.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12 MachineLearning GPU",
   "language": "python",
   "name": "ml312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
